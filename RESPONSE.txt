Thank you for the detailed reviews. I am especially glad to see two things:

  1. All reviews acknowledge this paper's core contribution to language design.
  2. The formal development in section 3 was clear.
     (Earlier versions tried to show **only** the interesting
     parts and came across as mysterious.)

### Major Misunderstandings and Questions

> **#31D**
> I think the paper could be strengthened by taking a deep engineering dive to
> making this system work in Typed Racket

This paper **is** the result of a deep engineering dive to making the 3-way
system work for all of Typed Racket. The combined system will be part of a
Typed Racket release in the near future.

> **#31D**
> - there are no interesting interactions between deep (natural) and
>   shallow checking

On the contrary, it is very interesting that natural and transient can coexist
but cannot cooperate further. This fact was not at clear at the start of this
research, and helps to motivate future work on shallow semantics that
use wrappers (such as in Castagna and Lanvin ICFP'17).

> **#31B**
> Looking at figure 4 alone, I cannot tell what makes shallow types
> shallow. Consider giving an example where code type-checks with shallow
> types but not deep types.
>
> **#31D**
> Prior work has used a separate category of ground types; writing
> $\lfloor \tau \rfloor$ is somewhat confusing, as it keeps $\tau$
> syntactically but ignores most of it semantically.
>
> **#31D**
> Section 5.2 was unconvincing for me: couldn't we say that untyped
> gains at least as much expressiveness over deep as shallow does?

Shallow and Deep types have similar static semantics. This is by design. They
are so similar that the Typed Racket implementation uses the same type
checker for each.

Section 5.2 is therefore significant because it shows that two languages with
the same notion of "well-typed" cannot run the same set of programs.

Ground types would not suffice because the surface type checker uses the full
type.

> **#31C**
> Q2 The notion of complete monitors is already presented in [19], and
>    the notion of spectrum together with a similar set of benchmarks are
>    presented in [18]. What's are the challenges and the relationship
>    with those works? Is it just a nice integration of both?

Prior meta-theory work was about finding tools to characterize the difference
between approaches to type enforcement. The prior implementation in [18]
(Greenman and Felleisen ICFP'18) covered Transient for a small functional
kernel in a separate, incompatible fork of Typed Racket.

This paper presents a practical and comprehensive language design. The
implementation covers modules, first-class classes & objects, meta-programming,
and other sophisticated Racket features. Complete monitoring, type soundness,
and the benchmarks are all tools that validate the design rather than primary
contributions.

> **#31E**
> I think more investigation of the theoretical model would be possible.  For
> example, variants of Blame Theorem and the dynamic gradual guarantee property
> [42] for the three-way language might be worth considering.  In particular, I
> expect dynamic gradual guarantee formally proves the benefits of integrating
> Deep and Shallow Typed Racket, which are spelled out at the beginning of
> Section 5.

The dynamic gradual guarantee (DGG) and the blame theorem are not part of the
validation because they study a separate dimension: the semantics of the
dynamic type. (Both Deep and Shallow can satisfy the DGG for the simple
types in the model.)

Whether the DGG (and term precision) could be adapted to Deep and Shallow mixes
is an interesting question for future work. However, Deep types are
well-characterized by complete monitoring and Shallow types are
well-characterized by type soundness.  Adding a new _relational_ property to the
toolbox may help to reason about changes in specific programs, but seems
unlikely to offer insights about the fundamental design questions.



### Other Clarifications

> **#31C**
> Q1 Why did you exclude dynamic types to meet the end-goal (lines 136-137)?
>    Just simplicity of the presentation or avoiding some unimportant
>    and tricky points?
>
> **#31D**
> Why does the paper choose to omit the dynamic type (line 137)? It's
> particular confusing because the surface language omits the dynamic
> type, but includes it in the "common evaluation syntax" (Figure
> 5). Typed Racket has the `Any` type... why doesn't the surface
> language here? It's particularly confusing because shallow types can
> be thought of has having implicit `Any` wherever first-order checks
> aren't inserted.
>
> **#31F**
> l135: What influence does losing dynamic type give to the design?

First off, `Any` is a top type in the model and in Typed Racket. It is similar
to `Object` in Java. It is not the dynamic type.

The main reason for excluding the dynamic type is that there are several
realistic gradual languages that do not support it in the theoretically-ideal
way. Typed Racket and Dart are two prominent examples.

The minor reason for excluding the dynamic type is that it would complicate
the model in ways that do not shed light on typed/untyped interactions (i.e.
by adding a type precision judgment, modifying the typing rules, and adding
a wrapper for values that get type-cast to dynamic).

> **#31A**
> I do wish the main paper had found room to include a bit of detail about the
> separate compilation issues, which I think are fairly important issues for
> implementations in general (whereas I agree with the paper that metaprogramming
> concerns, while important, wouldn't be as relevant to something like
> Typescript).

Section 4.1 is about separate compilation (though, it could be much clearer).


> **#31B**
> Can you comment on if there are other gradual type systems that can be
> mixed, and if so do you think your work hints at a recipe for such
> mixes?

This work provides a baseline for future mixes by combining two extreme
designs.  Other systems can apply the strategy from this work as a first step
and then look for ways to improve the interactions.

> **#31B**
> In the table in figure 4, why does every row have the same $T_1$?

This is a mistake. In the first two rows (for Deep and Shallow), there are only
3 possible choices for $T_1$. They are: $\tau_0$, $\lfloor \tau_0 \rfloor$, and $U$.


> **#31D**
> Figure 1 seems to me to be a Racket phenomenon (types mediating between two
> entirely untyped modules); I would expect a transient typing here to involve a
> module that had some first-order/shallow checks inserted.

Figure 1 has little to do with Racket; a transient module can sit between two
untyped ones. In transient, figure 1 would have one first-order check to ensure
that `text` is a function.

> **#31D**
> Another example of the Racket focus is setting $\mathsf{Nat} <:
> \mathsf{Int}$ and allowing overloading (line 328) to simulate a
> numeric tower. Overloading is an interesting feature to add, but
> raises questions that the paper does not answer (e.g., do the typed
> modes statically resolve overloading, or do all programs pay the price
> of dispatch?). I'd be more interested to see type tests and occurrence
> typing, to better study the interactions between deep and shallow
> checking.

The point of the subtyping judgment is to show its implications for type
enforcement, especially in the transient semantics. Prior work on transient
did not include subtyping, therefore it was not clear that a value could
cross a boundary with the type `(List Nat)` and then get used as a `(List Int)`
without any error.

The specific choice of `Nat` and `Int` keeps the examples simple. Union types
and objects would perhaps be clearer, but they would also complicate the model.

The paper does not discuss overloading, dispatch, or the numeric tower because
their details fall outside of the focus on type-enforcement.

Allowing occurrence types across a boundary is a difficult question for future
work.

> **#31D**
> The paper cites Greenman's dissertation as a way to say that such a
> connection couldn't be made stronger. Alternative approaches to
> shallow checking could have a tighter relationship---rather than only
> inserting checks at elimination forms and returns, you could _always_
> insert first-order checks (but no more). Such an approach has its
> roots in Findler, Guo, and Rogers's (IFL 2007) approach to lazy
> contract checking.

We agree that exploring implementations of shallow types that go beyond
transient is an important topic for future work.


> **#31D**
> Early work on transient semantics in Reticulated Python showed
> efficiency gains, especially when in PyPy... because the transient
> checks were just reproducing the checks that Python was going to do
> anyway. Is that happening here? That is, will the Racket runtime
> identify optimize duplicate checks (during compilation or in
> bytecode)?

The Racket runtime is not optimizing transient checks to the same extent that
PyPy would. Shallow Racket thus has the potential to run even faster in the
future.

> **#31D**
> I didn't understand what toggling (line 1130) was. Is The Worst D||S
> column indicating the worse runtime overhead for the best-possible mix
> of Deep and Shallow checking? I wish there an intuition for why there
> was a speedup. The idea that the sources of slowdown are complementary
> (line 1086) makes some sense, but I still don't get it. Is the idea
> that having shallow intermediate between deep and untyped avoids the
> worst of the slowdowns? Something else? Showing performance lattices
> might improve the situation, as would describing Figure 14 in more
> detail (is this the worst-case slowdown on a migration to a fully
> typed configuration, or something else?).

Toggling means using either Deep types or Shallow types. It does not allow for
mixes of Deep and Shallow.

Figure 14 is looking over each lattice three times: once to find the worst-case
of Deep types, once to find the worst-case of Shallow types, and once to find
the worst-case when each configuration uses all-Deep or all-Shallow depending
on which of the two is faster.

Another way to phrase the intuition is: the worst-case points in a Deep lattice
are usually not the same as in a Shallow lattice.


> **#31D**
> The claim in the conclusion for novelty is slightly weakened by the
> existence of options contracts (OOPSLA 2013), which serves a very
> similar purpose: it relaxes the contract (okay, not gradual typing)
> system in exchange for performance.

This paper contributes the first language design where programmers can choose
between two semantics for sound types.

Option contracts are indeed related (and belong in the related work!), but they
depend critically on wrappers. By contrast, natural uses wrappers and transient
is wrapper-free.

> **#31D**
> Is the rule in Figure 4 for shallow functions missing the
> $\lfloor-\rfloor$ on its argument in the conclusion? In Figure 4, why
> is subtyping only allowed at shallow types?

Yes! The rule for shallow functions needs a floor annotation.

Subtyping is allowed for all types. Figure 4 showed only the rule
for shallow types because the deep rule is straightforward. We will
reconsider this choice.

> **#31D**
> Some examples of source programs in Section 3 would be very
> helpful. For example, the description of modules is unclear (line
> 318): every switch between checking modes demands a `module`
> form... right?

Yes, every switch demands a `module` form.

> **#31D**
> In Figure 5, the type annotation on deep lambdas is just for the
> static checking of Figure 6; the type annotation on shallow lambdas is
> for both static _and_ dynamic checking. There's also a separate scan
> form, used for the results. There should be just one way to induce a
> shallow check, just as there's only one form of a guard.

The rule is that the `scan` keyword always corresponds to a shallow check.

Although it would be nice to use only one form, the `scan` for results cannot
be used for lambda checks without significantly complicating the model.


> **#31F**
> Considering the current theoretical development, I would like to see more
> evaluation of practical aspects of the three-way language.  While the paper
> evaluates the performance, I am also curious whether it affects the user
> experience such as debugging process.  One possible direction would be to apply
> the framework of Lazarek et al. [26] in the three-mix setting.

User experience is a great topic for future work, but out of scope for this
design paper.

> **#31F**
> fig 4: Please consider showing all the nine rules for the module constructor.
> In the current form, for example, any $T_1$ is allowed when $(L_0, T_0) = (D,
> \tau_0)$, but I think $T_1$ must be $\tau_0$, because otherwise Lemma A.1 in the
> supplementary material would not hold (as the corresponding rule in fig 18
> allows only $(D, \tau_0, \tau_0)$).

You are right. Figure 4 is too compressed.

> **#31F**
> fig 10, right-hand side: Why are happening errors equipped with labels?  When
> errors happen, are other labels in an evaluation context discarded?

Figure 10 keeps the context label around an error term to stay
visually-consistent with the other rules. It could be omitted because the model
is not interested in the owners of an error term (the question is
whether owners are consistent during evaluation).

> **#31F**
> Theorem 3.2: Does the bold 1 map only $\tau$ to $\tau$?  Then, why does language
> D satisfies $TS(\vdash_D, 1)$ even for $s_0$ that is typed at $U$ or $\lfloor
> \tau \rfloor$?  I'm confusing because Theorem 3.2 ensures, even if $s_0$ is
> typed at $U$ (resp. $\lfloor \tau \rfloor$), and if $s_0 \rightarrow^* v_0$,
> then $\vdash_D v_0 : 1(U)$ (resp. $1(\lfloor \tau \rfloor)$), but $1(U)$
> (resp. $1(\lfloor \tau \rfloor)$) may not be defined.  If it is defined, which
> types are assigned to them?  The typing judgment $\vdash_D$ requires the types
> to be some $\tau_0$, not $U$ nor $\lfloor \tau \rfloor$.

Good catch. The bold 1 indeed maps only $\tau$ to $\tau$, which means that type
soundness needs another premise to rule out $s_0$ that are typed at $U$ and at
shallow types.

> **#31F**
> l1226-1236: I don't think this paragraph shows a story to find fast-running
> configurations because it seems the entire script only runs in either Deep or
> Shallow Racket.

You are right.

